{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riturai1997/DQN_Feature_Fusion/blob/main/final_dqn_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVaB7WZJn0VF"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import pearsonr, entropy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, accuracy_score, f1_score, roc_auc_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from collections import deque, defaultdict\n",
        "import random\n",
        "import time\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnFlG2M56lqP",
        "outputId": "4ca0bfb0-ab7d-49f7-847f-1a31fb88a20d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5IX6y__6lmD"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_dataset(zip_file_path, attack_files):\n",
        "    df_list = []\n",
        "\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as z:\n",
        "        for file_name, label in attack_files.items():\n",
        "            with z.open(file_name) as attack_file:\n",
        "                attack_df = pd.read_csv(attack_file)\n",
        "\n",
        "                # Add label column\n",
        "                attack_df['Label'] = attack_df['Class'].apply(lambda x: 1 if x == 'T' else 0)\n",
        "\n",
        "\n",
        "                # Oversample minority class\n",
        "                t_class_size = attack_df[attack_df['Class'] == 'T'].shape[0]\n",
        "                r_class_size = attack_df[attack_df['Class'] == 'R'].shape[0]\n",
        "                majority_class = 'T' if t_class_size > r_class_size else 'R'\n",
        "                minority_class = 'R' if t_class_size > r_class_size else 'T'\n",
        "\n",
        "                if majority_class == 'T':\n",
        "                    minority_samples = attack_df[attack_df['Class'] == minority_class].sample(n=t_class_size, replace=True, random_state=42)\n",
        "                    majority_samples = attack_df[attack_df['Class'] == majority_class]\n",
        "                else:\n",
        "                    minority_samples = attack_df[attack_df['Class'] == minority_class].sample(n=r_class_size, replace=True, random_state=42)\n",
        "                    majority_samples = attack_df[attack_df['Class'] == majority_class]\n",
        "                minority_samples = minority_samples.sample(n=50000, random_state=42)\n",
        "                majority_samples = majority_samples.sample(n=50000, random_state=42)\n",
        "                attack_sampled_df = pd.concat([minority_samples, majority_samples], axis=0)\n",
        "                df_list.append(attack_sampled_df)\n",
        "\n",
        "\n",
        "    combined_df = pd.concat(df_list, axis=0)\n",
        "\n",
        "\n",
        "    def remove_single_quote(value):\n",
        "        return str(value).replace(\"'\", \"\")\n",
        "\n",
        "    def convert_exponential_to_hex(value):\n",
        "        try:\n",
        "            if isinstance(value, str) and 'E+' in value:\n",
        "                value = float(value)\n",
        "            hex_value = hex(int(value))[2:]\n",
        "            return hex_value.zfill(4).upper()\n",
        "        except ValueError:\n",
        "            return value\n",
        "\n",
        "    hex_columns = ['CAN ID','D[0]','D[1]','D[2]','D[3]','D[4]','D[5]','D[6]','D[7]']\n",
        "    for col in hex_columns:\n",
        "        combined_df[col] = combined_df[col].apply(remove_single_quote)\n",
        "        combined_df[col] = combined_df[col].apply(convert_exponential_to_hex)\n",
        "        combined_df[col] = combined_df[col].apply(lambda x: int(x, 16) if pd.notnull(x) else 0)\n",
        "\n",
        "    return combined_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dFgufp8n1Pv",
        "outputId": "4a2065df-036b-4f9a-8dce-569cff8c2aa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "\n",
        "def add_advanced_features(df):\n",
        "    \"\"\"Add sophisticated features for anomaly detection\"\"\"\n",
        "    # 1. Payload statistics\n",
        "    payload_cols = ['D[0]','D[1]','D[2]','D[3]','D[4]','D[5]','D[6]','D[7]']\n",
        "    df['Payload_Mean'] = df[payload_cols].mean(axis=1)\n",
        "    df['Payload_Std'] = df[payload_cols].std(axis=1)\n",
        "    df['Payload_Min'] = df[payload_cols].min(axis=1)\n",
        "    df['Payload_Max'] = df[payload_cols].max(axis=1)\n",
        "\n",
        "    # 2. Byte-level features\n",
        "    for i in range(8):\n",
        "        df[f'Byte_{i}_Delta'] = df[f'D[{i}]'].diff().abs().fillna(0)\n",
        "        df[f'Byte_{i}_Rolling_Mean'] = df[f'D[{i}]'].rolling(5, min_periods=1).mean()\n",
        "\n",
        "    # 3. Entropy and uniqueness\n",
        "    df['Payload_Entropy'] = df[payload_cols].apply(lambda x: entropy(pd.Series(x).value_counts(normalize=True)), axis=1)\n",
        "    df['Unique_Bytes'] = df[payload_cols].apply(lambda x: len(set(x)), axis=1)\n",
        "\n",
        "    # 4. Message frequency features\n",
        "    if 'Timestamp' in df.columns:\n",
        "        df['Msg_Interval'] = df.groupby('CAN ID')['Timestamp'].diff().fillna(0)\n",
        "        df['Msg_Frequency'] = 1/(df.groupby('CAN ID')['Msg_Interval'].transform('mean') + 1e-6)\n",
        "\n",
        "    # 5. Advanced position-specific features\n",
        "    df['Byte_0_Normalized'] = df['D[0]']/255\n",
        "    df['Byte_1_2_Ratio'] = np.where(df['D[1]']!=0, df['D[2]']/df['D[1]'], 0)\n",
        "    df['Byte_3_4_Diff'] = df['D[3]'] - df['D[4]']\n",
        "\n",
        "    # 6. CAN ID specific features\n",
        "    df['CAN_ID_Frequency'] = df.groupby('CAN ID')['CAN ID'].transform('count')\n",
        "    df['CAN_ID_Entropy'] = df.groupby('CAN ID')['D[0]'].transform(lambda x: entropy(pd.Series(x).value_counts(normalize=True)))\n",
        "\n",
        "    # 7. Payload change rate\n",
        "    df['Payload_Change_Rate'] = df[payload_cols].diff(axis=1).abs().sum(axis=1)\n",
        "\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHRNd2EH6ZR8"
      },
      "outputs": [],
      "source": [
        "\n",
        "class EnhancedDQN(nn.Module):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super(EnhancedDQN, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_size, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, action_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        return self.fc4(x)\n",
        "\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_size, action_size):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=100000)\n",
        "        self.gamma = 0.99\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.learning_rate = 0.001\n",
        "        self.batch_size = 128\n",
        "\n",
        "        self.model = EnhancedDQN(state_size, action_size).to(device)\n",
        "        self.target_model = EnhancedDQN(state_size, action_size).to(device)\n",
        "        self.target_model.load_state_dict(self.model.state_dict())\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.loss_fn = nn.SmoothL1Loss()\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def act(self, state):\n",
        "        if random.random() <= self.epsilon:\n",
        "            return random.randint(0, self.action_size - 1)\n",
        "        state = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
        "        self.model.eval()  # Set model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            act_values = self.model(state)\n",
        "        return torch.argmax(act_values).item()\n",
        "\n",
        "    def replay(self):\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return\n",
        "\n",
        "        minibatch = random.sample(self.memory, self.batch_size)\n",
        "        states = torch.FloatTensor(np.array([t[0] for t in minibatch])).to(device)\n",
        "        actions = torch.LongTensor(np.array([t[1] for t in minibatch])).to(device)\n",
        "        rewards = torch.FloatTensor(np.array([t[2] for t in minibatch])).to(device)\n",
        "        next_states = torch.FloatTensor(np.array([t[3] for t in minibatch])).to(device)\n",
        "        dones = torch.FloatTensor(np.array([t[4] for t in minibatch])).to(device)\n",
        "\n",
        "        self.model.train()  # Set model to training mode\n",
        "        current_q = self.model(states).gather(1, actions.unsqueeze(1))\n",
        "        next_q = self.target_model(next_states).max(1)[0].detach()\n",
        "        target = rewards + (1 - dones) * self.gamma * next_q\n",
        "\n",
        "        loss = self.loss_fn(current_q.squeeze(), target)\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "    def decay_epsilon(self):\n",
        "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
        "\n",
        "    def update_target_model(self):\n",
        "        self.target_model.load_state_dict(self.model.state_dict())\n",
        "\n",
        "class CarHackingEnv:\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.current_index = 0\n",
        "        self.max_steps = len(X)\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_index = 0\n",
        "        return self.X[self.current_index]\n",
        "\n",
        "    def step(self, action):\n",
        "        true_label = self.y[self.current_index]\n",
        "        reward = 20 if action == true_label else -10\n",
        "        self.current_index += 1\n",
        "        done = self.current_index >= self.max_steps\n",
        "        next_state = self.X[self.current_index] if not done else None\n",
        "        return next_state, reward, done, {'true_label': true_label}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaDhsBtX68F2"
      },
      "outputs": [],
      "source": [
        "car_hacking_path = '/content/drive/My Drive/Survival_Analysis/SONATA.zip'\n",
        "car_hacking_files = {\n",
        "    'Flooding.csv': 2,\n",
        "    'Malfunction.csv': 1,\n",
        "    'Fuzzy.csv': 3\n",
        "}\n",
        "\n",
        "df = load_and_preprocess_dataset(car_hacking_path, car_hacking_files)\n",
        "df = add_advanced_features(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtZmO3il7GV_"
      },
      "outputs": [],
      "source": [
        "# Select features - now including all CAN ID and payload bytes plus engineered features\n",
        "selected_features = [\n",
        "    'CAN ID', 'D[0]', 'D[1]', 'D[2]', 'D[3]', 'D[4]', 'D[5]', 'D[6]', 'D[7]',\n",
        "    'Payload_Mean', 'Payload_Std', 'Payload_Entropy', 'Unique_Bytes',\n",
        "    'Msg_Frequency', 'Byte_1_2_Ratio', 'Byte_3_4_Diff', 'CAN_ID_Frequency',\n",
        "    'CAN_ID_Entropy', 'Payload_Change_Rate'\n",
        "]\n",
        "\n",
        "X = df[selected_features]\n",
        "y = df['Label']\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert to tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
        "y_train_tensor = torch.LongTensor(y_train.values).to(device)\n",
        "X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
        "y_test_tensor = torch.LongTensor(y_test.values).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "ELOt9ZXs9Mh8",
        "outputId": "2cecb0ac-ca22-48d7-c1db-6b8541add873"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode 0, Reward: 1205970.00, Test Accuracy: 0.7935, Epsilon: 0.9950\n",
            "Episode 10, Reward: 1369440.00, Test Accuracy: 0.9541, Epsilon: 0.9464\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3ee8bfb2eb9f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-04be5c2eba21>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mact_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-04be5c2eba21>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize environment and agent\n",
        "env = CarHackingEnv(X_train, y_train.values)\n",
        "state_size = X_train.shape[1]\n",
        "action_size = 2\n",
        "agent = DQNAgent(state_size, action_size)\n",
        "\n",
        "# Training parameters\n",
        "episodes = 300\n",
        "update_target_every = 10\n",
        "batch_size = 128\n",
        "\n",
        "# Training loop\n",
        "best_accuracy = 0\n",
        "for episode in range(episodes):\n",
        "    state = env.reset()\n",
        "    total_reward = 0\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        action = agent.act(state)\n",
        "        next_state, reward, done, info = env.step(action)\n",
        "        agent.remember(state, action, reward, next_state, done)\n",
        "        state = next_state\n",
        "        total_reward += reward\n",
        "\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    # Experience replay\n",
        "    for _ in range(5):  # Multiple updates per episode\n",
        "        agent.replay()\n",
        "\n",
        "    agent.decay_epsilon()\n",
        "\n",
        "    # Update target network periodically\n",
        "    if episode % update_target_every == 0:\n",
        "        agent.update_target_model()\n",
        "\n",
        "    # Evaluation\n",
        "    if episode % 10 == 0:\n",
        "        with torch.no_grad():\n",
        "            test_outputs = agent.model(X_test_tensor)\n",
        "            _, predicted = torch.max(test_outputs, 1)\n",
        "            accuracy = accuracy_score(y_test_tensor.cpu(), predicted.cpu())\n",
        "\n",
        "            if accuracy > best_accuracy:\n",
        "                best_accuracy = accuracy\n",
        "                torch.save(agent.model.state_dict(), 'best_dqn_model.pth')\n",
        "\n",
        "            print(f\"Episode {episode}, Reward: {total_reward:.2f}, Test Accuracy: {accuracy:.4f}, Epsilon: {agent.epsilon:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmqkVvqE9Uz6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}